{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"demoTrainAndTest.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMe79vL2/gon/aYeuKXwZIz"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PE45_ALlctOf"},"source":["## Basic Model Setting"]},{"cell_type":"code","metadata":{"id":"yN1tYCLFctOg"},"source":["# install the package for videogenerator used in training\r\n","!pip install keras-video-generators"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"46zvvFKtctOl"},"source":["#get access from google drive\r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n","%cd /"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tNu6Sy2ActOn"},"source":["#set the directory for training data\r\n","train_dir='/content/gdrive/My Drive/CSCE636_Deep_Learning/Model/Custom_Dataset/Custom_Dataset4/{classname}/*'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9liAFybFctOq"},"source":["import keras\r\n","from keras_video import VideoFrameGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xo3wiW6CctOr"},"source":["#global parameters for training\r\n","size = (224, 224)    # the input image size is (224,224,4)\r\n","channels = 3\r\n","N_frames = 8       # each video is cut into 8 frames\r\n","Batch_size = 8\r\n","classes=2          #two classes: one for target action, the other is for other actions\r\n","train_validate_split=0.3  #30% data used for validation  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"shaB5RhoctOs"},"source":["# for data augmentation\r\n","from keras_preprocessing.image import ImageDataGenerator\r\n","data_aug = ImageDataGenerator(\r\n","    zoom_range=.1,\r\n","    horizontal_flip=True,\r\n","    rotation_range=8,\r\n","    width_shift_range=.2,\r\n","    height_shift_range=.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qtUAzTRxctOt"},"source":["#set the videogenerator for the training process\r\n","train_gen = VideoFrameGenerator( \r\n","    glob_pattern=train_dir,\r\n","    nb_frames=N_frames,\r\n","    split_val=train_validate_split, \r\n","    shuffle=True,     #shuffle the sample for training\r\n","    batch_size=Batch_size,\r\n","    target_shape=size,\r\n","    nb_channel=channels,\r\n","    transformation=data_aug,  #apply data augmentaion for the generated frames\r\n","    use_frame_cache=False)    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bGrGKLnectOv"},"source":["#set the videogenerator for the validation process\r\n","validation_gen= train_gen.get_validation_generator()  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u_kQ6fthctOw"},"source":["#show some sample frames generated from videogenerator\r\n","from keras_video import utils as ku\r\n","ku.show_sample(train_gen, random=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ccBDyNEvVNms"},"source":["## Model Setting of Neural Network: CNN (Fine tuning from MobileNetV2) + GRU + Classifier Layers"]},{"cell_type":"code","metadata":{"id":"2kpIi0gxVn0P"},"source":["# fine tuning MobileNetV2\r\n","def build_mobilenet(shape=(224, 224, 3), nbout=2):\r\n","    model = keras.applications.MobileNetV2(\r\n","        include_top=False,\r\n","        input_shape=shape,\r\n","        weights='imagenet')\r\n","    # Keep 9 layers to train\r\n","    trainable = 9\r\n","    for layer in model.layers[:-trainable]:\r\n","        layer.trainable = False\r\n","    for layer in model.layers[-trainable:]:\r\n","        layer.trainable = True\r\n","    output = keras.layers.GlobalMaxPool2D()\r\n","    return keras.Sequential([model, output])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zlCWtxQ8Wu4Q"},"source":["# the sturctue of the Neural Network \r\n","from keras.layers import TimeDistributed, GRU, LSTM, Dense, Dropout\r\n","def action_model(shape=(8, 224, 224, 3), nbout=2):\r\n","    # create the convnet with (224, 224, 3) input shape\r\n","    convnet = build_mobilenet(shape[1:])\r\n","    \r\n","    # create the final model\r\n","    model = keras.Sequential()\r\n","    # add the convnet with (8, 224, 224, 3) shape\r\n","    model.add(TimeDistributed(convnet, input_shape=shape))\r\n","    # add GRU\r\n","    model.add(GRU(64))\r\n","    # add the classification layers\r\n","    model.add(Dense(1024, activation='relu'))\r\n","    model.add(Dropout(.5))\r\n","    model.add(Dense(512, activation='relu'))\r\n","    model.add(Dropout(.5))\r\n","    model.add(Dense(128, activation='relu'))\r\n","    model.add(Dropout(.5))\r\n","    model.add(Dense(64, activation='relu'))\r\n","    model.add(Dense(nbout, activation='softmax'))\r\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MT_RV7lDWAE6"},"source":["from keras import optimizers\r\n","Inshape=(N_frames,) + size + (channels,) #(8, 224, 224, 3)\r\n","model = action_model(Inshape, classes)\r\n","optimizer = optimizers.Adam(0.001)     #Use Adam as optimizers, set learning rate as 0.001\r\n","model.compile(\r\n","    optimizer,\r\n","    'binary_crossentropy',        #use binary crossentropy as the loss function\r\n","    metrics=['acc',keras.metrics.FalsePositives(),keras.metrics.FalseNegatives()]\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VUutUqy8PHzh"},"source":["## Train the Model and test its performance on validation set"]},{"cell_type":"code","metadata":{"id":"LXGTNJVyXTjv"},"source":["#training the model\r\n","epochs=30                                              # set the epochs=30 since longer training causes over-fitting\r\n","callbacks = [            \r\n","    keras.callbacks.ModelCheckpoint(\r\n","        '/content/gdrive/My Drive/CSCE636_Deep_Learning/Model/chkp/weight_custom.hdf5',   #save the weights with best performance\r\n","        verbose=1,\r\n","        save_weights_only=True,\r\n","        save_best_only=True,),\r\n","]\r\n","#train the model and see the performance on training and validation set\r\n","history=model.fit_generator(\r\n","    train_gen,\r\n","    validation_data=validation_gen,       \r\n","    verbose=1,\r\n","    epochs=epochs,\r\n","    callbacks=callbacks\r\n",")\r\n","model.save('/content/gdrive/My Drive/CSCE636_Deep_Learning/Model/chkp/model_custom.h5')       #save the trained model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZUoLpo-JXWR3"},"source":["#plot the results\r\n","import matplotlib.pyplot as plt\r\n","acc = history.history['acc']\r\n","val_acc = history.history['val_acc']\r\n","loss = history.history['loss']\r\n","val_loss =history.history['val_loss']\r\n","\r\n","epochs=range(1,len(acc)+1)\r\n","\r\n","plt.plot(epochs, acc, 'r', label='Training acc')\r\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\r\n","plt.title('Training and validation accuracy')\r\n","plt.legend()\r\n","\r\n","plt.figure()\r\n","\r\n","plt.plot(epochs, loss, 'r', label='Training loss')\r\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\r\n","plt.title('Training and validation loss')\r\n","plt.legend()\r\n","\r\n","plt.show()"],"execution_count":null,"outputs":[]}]}