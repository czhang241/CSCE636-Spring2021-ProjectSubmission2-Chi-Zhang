{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"demoApplyToVideo.ipynb","provenance":[],"collapsed_sections":["3LJeWKyFNg1b","xFVRCg7Nl9GJ"],"authorship_tag":"ABX9TyMlVHVF5hXup0PBnMImGbtj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8vRGYin_CW4k"},"source":["**The procedure goes on three steps: trim the video to video clips, get the classification results from the video clips and output the classification results in json files**"]},{"cell_type":"markdown","metadata":{"id":"3LJeWKyFNg1b"},"source":["## Trim video to video clips and rename them"]},{"cell_type":"code","metadata":{"id":"KZzJH353NgRC"},"source":["# install the package moviepy \r\n","!pip install moviepy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i19aHLKvN_yB"},"source":["# get access from the google drive\r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n","%cd /"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ta_RMFw-OEBG"},"source":["# Import everything needed to edit video clips\r\n","from moviepy.editor import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jARIN7ksPtXB"},"source":["#set the video's original directory and the directory for the video clips\r\n","import os\r\n","import numpy as np\r\n","import math\r\n","\r\n","base_dir='content/gdrive/My Drive/CSCE636_Deep_Learning/Action Detection_1'   #video's original directory\r\n","video_list=os.listdir(base_dir)\r\n","dst_dir='content/gdrive/My Drive/CSCE636_Deep_Learning/Action_Detect_Clips/Test1/Test1'  #two recursive test folders are needed because the videogenerator I used requires them\r\n","os.mkdir(dst_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xBXCUA8APldh"},"source":["# clip video to video clips every 6 seconds  \r\n","i=0\r\n","interval=6\r\n","for video in video_list:\r\n","  video_src_dir=os.path.join(base_dir,video)\r\n","  myclip = VideoFileClip(video_src_dir,audio=False)\r\n","  i +=1\r\n","  for time in np.arange(myclip.duration // interval):\r\n","    video_dst=video.split(\".\")[0]+\"+\"+str(time*interval)+\"+\"+str(time*interval+2)+'.mp4'    #rename the video clips as videoId+start time+end time\r\n","    video_dst_dir=os.path.join(dst_dir,video_dst)\r\n","    output_clip=myclip.subclip(t_start=time*interval, t_end=time*interval+2)\r\n","    output_clip.write_videofile(video_dst_dir) \r\n","    print('Clipping:',i,' Duration:',myclip.duration)\r\n","    print('Clipping time:',time*interval,time*interval+2)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GNVOePv5H0WA"},"source":["## Predict on test video"]},{"cell_type":"code","metadata":{"id":"jDQcPi_iiBEv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614896020557,"user_tz":360,"elapsed":3257,"user":{"displayName":"c z","photoUrl":"","userId":"14928481541525258630"}},"outputId":"6530e519-cef1-414f-a620-7b89423e6c85"},"source":["#install the package for the video generators\r\n","!pip install keras-video-generators"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras-video-generators in /usr/local/lib/python3.7/dist-packages (1.0.14)\n","Requirement already satisfied: keras>=2 in /usr/local/lib/python3.7/dist-packages (from keras-video-generators) (2.4.3)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from keras-video-generators) (4.1.2.30)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from keras-video-generators) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-video-generators) (1.19.5)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2->keras-video-generators) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2->keras-video-generators) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2->keras-video-generators) (2.10.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras-video-generators) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras-video-generators) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras-video-generators) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras-video-generators) (1.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2->keras-video-generators) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k7rGvci9jOXw"},"source":["#get access from google drive\r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n","%cd /"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qo3sH4T7L_N4"},"source":["#set the directory of training data and test data\r\n","train_dir='/content/gdrive/My Drive/CSCE636_Deep_Learning/Model/Custom_Dataset/Custom_Dataset4/{classname}/*'\r\n","\r\n","testset_name='Test1'\r\n","test_dir='content/gdrive/My Drive/CSCE636_Deep_Learning/Action_Detect_Clips/'+testset_name+'/{classname}/*'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xrY14jR4hgd9"},"source":["#import the model I trained\r\n","import keras \r\n","model_name='model_custom4_1'\r\n","model = keras.models.load_model('content/gdrive/My Drive/CSCE636_Deep_Learning/Model/chkp/'+model_name+'.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TKCK1px9iaW8"},"source":["#keep the global parameters as the training model\r\n","size = (224, 224)\r\n","channels = 3\r\n","N_frames = 8\r\n","Batch_size = 8\r\n","classes=2\r\n","train_validate_split=0.3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T1mxw8OZjZ_M"},"source":["# from training data generator to get labels\r\n","from keras_video import VideoFrameGenerator\r\n","from keras_preprocessing.image import ImageDataGenerator\r\n","\r\n","data_aug = ImageDataGenerator(\r\n","    zoom_range=.1,\r\n","    horizontal_flip=True,\r\n","    rotation_range=8,\r\n","    width_shift_range=.2,\r\n","    height_shift_range=.2)\r\n","\r\n","train_gen = VideoFrameGenerator( \r\n","    glob_pattern=train_dir,\r\n","    nb_frames=N_frames,\r\n","    split_val=train_validate_split, \r\n","    shuffle=True,\r\n","    batch_size=Batch_size,\r\n","    target_shape=size,\r\n","    nb_channel=channels,\r\n","    transformation=data_aug,\r\n","    use_frame_cache=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NR9WGsIYH27F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614896109911,"user_tz":360,"elapsed":92584,"user":{"displayName":"c z","photoUrl":"","userId":"14928481541525258630"}},"outputId":"93ec491e-47b8-4de7-c148-afbd83a177ca"},"source":["#set test data generator for testing\r\n","test_gen = VideoFrameGenerator(\r\n","    glob_pattern=test_dir,\r\n","    nb_frames=N_frames, \r\n","    batch_size=1,\r\n","    target_shape=size,\r\n","    nb_channel=channels,\r\n","    shuffle=False,\r\n","    use_frame_cache=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total data: 1 classes for 3284 files for train\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"845znKaxOTT0"},"source":["#show the number of video clips for testing\r\n","len(test_gen.files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nuSDhS4tImf8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a87c2a61-2a42-4ba7-afdf-97e80ba70a7d"},"source":["#prediction using test data\r\n","predict = model.predict_generator(test_gen)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"HhT10zFbOdU2"},"source":["#show the prediction results\r\n","preds_cls_idx = predict.argmax(axis=-1)\r\n","print(preds_cls_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mNKMsergRth_"},"source":["#show the prediction files' dimension\r\n","predict.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"53iQgOy_O2EK"},"source":["#show the classes order \r\n","train_gen.classes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"evTxa5R2VoZe"},"source":["#make a dictionary for the labels and classes generated by model\r\n","class_names = sorted(train_gen.classes) # Sorting them\r\n","name_id_map = dict(zip(class_names, range(len(class_names))))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4wC6MBFqWkte"},"source":["#show the dictionary of lables\r\n","name_id_map"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XQsah1PW8Iw"},"source":["#show the testing data\r\n","from pandas import DataFrame\r\n","FileName=DataFrame(test_gen.files, columns=['FileName'])\r\n","FileName"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ph0pFB2Rccyn"},"source":["#show the prediction results\r\n","ClassName=DataFrame(preds_cls_idx, columns=['ClassName'])\r\n","ClassName.columns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKTyAnwvZbQZ"},"source":["#combine the testing data with their prediciton results\r\n","import pandas as pd\r\n","\r\n","output=pd.concat([FileName, ClassName], axis=1)\r\n","output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wpX6dVyr7DnJ"},"source":["#keep the target action for output\r\n","output_json=output[output.ClassName==0]\r\n","output_json.FileName"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xFVRCg7Nl9GJ"},"source":["## Write json file"]},{"cell_type":"code","metadata":{"id":"kZnjsvdymbe2"},"source":["# get access from google drive\r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n","%cd /"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GvCOVTThmbe2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614895731567,"user_tz":360,"elapsed":402,"user":{"displayName":"c z","photoUrl":"","userId":"14928481541525258630"}},"outputId":"46785561-e4bc-4381-fdb5-3bbf5edc8984"},"source":["# set the directory for the output json file\r\n","import os\r\n","json_dir='/content/gdrive/My Drive/CSCE636_Deep_Learning/Output/Submission2'\r\n","try: \r\n","  os.mkdir(json_dir)\r\n","except:\r\n","  print(\"Folder exists\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Folder exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OCykzl-bhEa_"},"source":["import json\r\n","import os\r\n","import numpy as np\r\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rqwpuMlObue"},"source":["#show the number of videoclips which contain the target action (Clapping_hands)\r\n","len(output_json)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CEvbIdpimTmp"},"source":["#show the the videoId, start time and end time of the output videoclips\r\n","for address in output_json['FileName']:\r\n","  video_name=address.split(\"/\")[-1]\r\n","  print(video_name.split(\"+\")[0],video_name.split(\"+\")[1],video_name.split(\"+\")[2].split(\".\")[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Vr6euEZwRGQ"},"source":["#output the json file\r\n","## the information of every 300 videoclips are combined in a json file\r\n","df=[]\r\n","nick_name=\"CSCE636Spring2021-RZ241-2\"\r\n","label=\"Clapping-hands\"\r\n","\r\n","max_number=300\r\n","file_num=0\r\n","name_base=\"ResultOfDetection_RZ241_submission2_\"+model_name+\"_\"+testset_name\r\n","video_count=0\r\n","\r\n","for address in output_json['FileName']:\r\n","  video_count +=1\r\n","  video_name=address.split(\"/\")[-1]\r\n","  videoid=video_name.split(\"+\")[0]\r\n","  video_start=video_name.split(\"+\")[1]\r\n","  video_end=video_name.split(\"+\")[2].split(\".\")[0]\r\n","  df_tmp={\"videoId\":videoid,\"type\":\"segment\",\"startTime\":float(video_start),\"endTime\":float(video_end),\"observer\":nick_name,\"isHuman\":False,\r\n","       \"confirmedBySomeone\": False,\"rejectedBySomeone\": False,\"observation\":{\"label\": label,\"labelConfidence\": 0.85}}\r\n","  df.append(df_tmp)\r\n","  \r\n","  if (video_count % max_number==0):\r\n","    file_num +=1\r\n","    filename=name_base+str(file_num)+\".json\"\r\n","    with open(os.path.join(json_dir,filename), 'w',encoding='utf-8') as f:\r\n","      json.dump(df, f,ensure_ascii=False, indent=4)\r\n","    df=[]\r\n","\r\n","if (video_count % max_number>0):\r\n","  file_num +=1\r\n","  filename=name_base+str(file_num)+\".json\"\r\n","  with open(os.path.join(json_dir,filename), 'w',encoding='utf-8') as f:\r\n","    json.dump(df, f,ensure_ascii=False, indent=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2-LPe0v5x7Ey"},"source":[""],"execution_count":null,"outputs":[]}]}